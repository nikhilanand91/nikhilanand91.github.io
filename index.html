<!DOCTYPE html>
<html lang="en">
<head>
    <!-- Google tag (gtag.js) -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=G-JZX1D0K3XG"></script>
    <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'G-JZX1D0K3XG');
    </script>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Nikhil Anand</title>
    <link rel="stylesheet" href="style.css">
    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link href="https://fonts.googleapis.com/css2?family=Domine:wght@400;700&display=swap" rel="stylesheet">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.5.2/css/all.min.css" integrity="sha512-SnH5WK+bZxgPHs44uWIX+LLJAJ9/2PkPKZ5QiAj6Ta86w+fsb2TkcmfRyVX3pBnMFcV7oQPJkl9QevSCWr3W6A==" crossorigin="anonymous" referrerpolicy="no-referrer" />
</head>
<body>

    <div class="container">
        <header>
            <img src="profile2.jpg" alt="A photo of me" class="profile-photo">
            <h1>Nikhil Anand</h1>
            <div class="icon-links">
                <a href="mailto:nkhlanand at gmail dot com" aria-label="Email">
                    <i class="fas fa-envelope"></i>
                </a>
                <a href="https://github.com/nikhilanand91" target="_blank" aria-label="GitHub">
                    <i class="fab fa-github"></i>
                </a>
                <a href="https://scholar.google.com/citations?hl=en&user=L-QbDz8AAAAJ&view_op=list_works&sortby=pubdate" target="_blank" aria-label="Google Scholar">
                    <i class="fas fa-graduation-cap"></i>
                </a>
                <a href="https://wandb.ai/nikhilanand91" target="_blank" aria-label="Weights & Biases">
                    <i class="fas fa-wand-magic-sparkles"></i>
                </a>
                <a href="https://x.com/nikhil_anand91" target="_blank" aria-label="X Profile">
                    <i class="fab fa-x-twitter"></i>
                </a>
            </div>
        </header>

        <main>
            <section id="about">
                <!-- <h2>Hello</h2> -->
                <p>
                    I'm currently a research scientist at the <a href="https://kempnerinstitute.harvard.edu/">Kempner Institute</a> at Harvard working on machine learning and artificial intelligence.
                    I also have a background in theoretical high-energy physics.
                </p>

                <p>

                    Before joining Kempner, I was at Amazon (in the organization formerly known as Alexa AI) where I worked on production speech/language models as a research scientist.
                    Before that, I was a <a href="https://bootstrapcollaboration.com/">Simons Collaboration</a> postdoctoral fellow at McGill University, working on topics in high-energy theoretical physics.

                </p>

                <p>
                    I completed my PhD in 2018 at Johns Hopkins University under the supervision of <a href="https://sites.krieger.jhu.edu/jared-kaplan/" target="_blank">Jared Kaplan</a>.
                    I did my undergrad at UC Berkeley, where I majored in physics and worked on <a href="https://www.ocf.berkeley.edu/~nanand/software/dmformfactor/" target="_blank">dark matter detection</a>.
                </p>
            </section>

            <section id="research">
                <h2>Research Interests</h2>

                My work focuses on building and scaling up foundation models.  Some specific research questions I've been thinking about recently are:
                <ul>
                    <li>Quantization: what precision is needed to (pre/post)-train large models and what is its interaction with the architecture?</li>
                    <li>Post-training: how can we set up post-training for agentic tasks without clear verifiable rewards or with long horizons?</li>
                    <li>Scaling systems: what are the systems-related challenges associated with scaling up transformers?</li>
                </ul>
                Feel free to reach out if you want to chat about any of these or related topics!
            </section>

            <section id="publications">
                <h2>Preprints and Publications</h2>
                <p>
                    A full list is available on 
                    <a href="https://scholar.google.com/citations?hl=en&user=L-QbDz8AAAAJ&view_op=list_works&sortby=pubdate">my Google Scholar</a>.
                </p>
            </section>

            <section id="writing">
                <h2>Blog Posts / Teaching</h2>
                <ul>
                    <li><a href="https://kempnerinstitute.harvard.edu/research/deeper-learning/characterization-and-mitigation-of-training-instabilities-in-microscaling-formats/" target="_blank">Blog post on our work on low-precision training instabilities</a></li>
                    <li><a href="https://kempnerinstitute.harvard.edu/research/deeper-learning/loss-to-loss-prediction/" target="_blank">Blog post on our work on loss-to-loss-prediction</a></li>
                    <li> (Fall 2024) Co-taught Kempner Institute introductory workshop on building transformers: <a href="https://www.dropbox.com/scl/fi/5pbr4g4bgm2ssua6vrdu3/Kempner_Building_a_Transformer_from_Scratch_Workshop.pdf?rlkey=nu5gj80ju9f0iecvpxp88g8js&st=spqdhmuj&dl=0" target="_blank">slides</a>
                    and <a href="https://github.com/KempnerInstitute/transformer-workshop/tree/main" target="_blank">Jupyter notebook exercises (with solutions)</a>. </li>
                    <li>
                        (Fall 2024) Guest lecture slides for <a href="https://shamulent.github.io/CS_2281_2024.html" target="_blank">CS 2281R</a> about <a href="https://www.dropbox.com/scl/fi/ublytq30ac039n6xgefc2/Lec1_intro.pdf?rlkey=3yp2o60sn35imkw3x8bmwp0vh&st=940lvu0f&dl=0" target="_blank">hardware, DDP, checkpointing, and compute primitives</a> and <a href="https://www.dropbox.com/scl/fi/q3qlzcamqq470ce5zitr8/Lec8_parallel.pdf?rlkey=3iirums9ypr83guvpfhemkby0&st=viltiy1f&dl=0" target="_blank">parallelization</a>.
                    </li>

                </ul>
            </section>

            <section id="misc">
                <h2>Fun</h2>
                <ul>
            
                    When I need to step away from the screen, youâ€™ll usually find me at a squash court, taking a long walk, biking, or lifting weights.

                    I <a href="https://nkhlanand.myportfolio.com/sample-photos" target="_blank">also enjoy photography</a> and usually bring my trusty Nikon when I'm traveling.
                    
                </ul>
            </section>

        </main>
    </div>

</body>
</html>